{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overview of this notebook\n",
    "\n",
    "* overview of `sktime` as a framework - estimators modules, library, data\n",
    "* overview of learning tasks in `sktime`\n",
    "* data formats used in `sktime`, import and validity checking\n",
    "* basic vignettes for learning tasks - forecasting, classification, regression, clustering & more\n",
    "* searching the library for estimators, tag system\n",
    "* estimator level dependency management\n",
    "* creating your own estimator, to `sktime`, or for third party use (closed or open) - short primer"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. `sktime` in a nutshell - learning tasks, modules, library, data\n",
    "\n",
    "**A) `sktime` is a modular framework for multiple learning tasks**\n",
    "\n",
    "Example: forecasting (predict future of ts), classification (predict label of ts)\n",
    "\n",
    "**B) estimators/algorithms are of a scientific type = which task do they solve?**\n",
    "\n",
    "Example: ARIMA is a forecaster; knn with time series distance is classifier\n",
    "\n",
    "**C) all estimators of a certain scitype have the same module interface**\n",
    "\n",
    "Example: all forecasters classes have `fit` / `predict` with same contract\n",
    "\n",
    "**D) `sktime` is a library which allows browsing of integrated estimators**\n",
    "\n",
    "Example: search for all forecasters that are natively multivariate\n",
    "\n",
    "**E) `sktime` is a mini-package manager for estimators and their dependencies**\n",
    "\n",
    "Example: `ARIMA` class requires `pmdarima`, but `sktime` itself does not\n",
    "\n",
    "**F) `sktime` is extensible, write your own 3rd party plugins (open or closed)**\n",
    "\n",
    "Example: forecaster in 3rd party codebase, plug & plays to `sktime` and test framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Showcase with code vignettes\n",
    "\n",
    "The above, with code. We revisit in more detail later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **A) `sktime` is a modular framework for multiple learning tasks**\n",
    "\n",
    "Vignettes for forecasting and classification:\n",
    "(we'll go into data types etc later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "import numpy as np\n",
    "\n",
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "# y is a pd.Series at monthly frequency\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "# this specifies a prediction 3 years ahead\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "# forecaster is now a forecaster object of type NaiveForecaster\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y, fh=fh)\n",
    "# forecaster changes state to \"fitted\"\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict()\n",
    "# y_pred is the forecasted time series, a pd.Series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "# step 1 - specify training data\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "# X_train is 3D numpy array holding multiple instances of time series\n",
    "# y_train is 1D numpy array with training labels for these instances\n",
    "\n",
    "# step 2 - specify data to predict labels for\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new[:2]\n",
    "# X_new is a 3D numpy array with the instances to label\n",
    "\n",
    "# step 3 - specify the classifier\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)\n",
    "# clf is a classifier object of type KNeighborsTimeSeriesClassifier\n",
    "# it consists of other sktime objects, mean_eucl_dist is a distance object\n",
    "\n",
    "# step 4 - fitting the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "# clf changes state to \"fitted\"\n",
    "\n",
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)\n",
    "# y_pred is the predicted labels, an 1D numpy array"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **B) estimators/algorithms are of a scientific type = which task do they solve?**\n",
    "\n",
    "`NaiveForecaster` is a forecaster; `KNeighborsTimeSeriesClassifier` is a classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.naive import NaiveForecaster\n",
    "from sktime.registry import scitype\n",
    "\n",
    "scitype(NaiveForecaster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.registry import scitype\n",
    "\n",
    "scitype(KNeighborsTimeSeriesClassifier)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**C) all estimators of a certain scitype have the same module interface**\n",
    "\n",
    "C1 - the `NaiveForecaster` can be switched out for any forecaster in the base vignette\n",
    "\n",
    "Only step 3 - specification changes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_airline\n",
    "from sktime.forecasting.arima import ARIMA\n",
    "import numpy as np\n",
    "\n",
    "# step 1: data specification\n",
    "y = load_airline()\n",
    "\n",
    "# step 2: specifying forecasting horizon\n",
    "fh = np.arange(1, 37)\n",
    "\n",
    "# step 3: specifying the forecasting algorithm\n",
    "# forecaster = NaiveForecaster(strategy=\"last\", sp=12)\n",
    "forecaster = ARIMA()\n",
    "\n",
    "# step 4: fitting the forecaster\n",
    "forecaster.fit(y)\n",
    "\n",
    "# step 5: querying predictions\n",
    "y_pred = forecaster.predict(fh)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C2 - `fit` and `predict` are the same for both!\n",
    "\n",
    "`fit(self, y, X=None, fh=None)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?ARIMA.fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "?NaiveForecaster.fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for classifiers, signature is different: `fit(X, y)`\n",
    "\n",
    "but the same for all classifiers!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "KNeighborsTimeSeriesClassifier.fit"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **D) `sktime` is a library which allows browsing of integrated estimators**\n",
    "\n",
    "Example: search for all forecasters that can make probabilistic predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"forecaster\", filter_tags={\"capability:pred_int\": True}, as_dataframe=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all objects in `sktime` are tagged with metadata:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ARIMA().get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "list all tags that apply to forecasters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_tags\n",
    "\n",
    "all_tags(\"forecaster\", as_dataframe=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **E) `sktime` is a mini-package manager for estimators and their dependencies**\n",
    "\n",
    "Example: `ARIMA` class requires `pmdarima`, but `sktime` itself does not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.forecasting.arima import ARIMA\n",
    "\n",
    "ARIMA.get_class_tag(\"python_dependencies\")\n",
    "# this requires the pmdarima package\n",
    "# the result is a PEP 440 compatible requirement string"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "by default, dependencies are checked at instantiation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sktime.forecasting.fbprophet import Prophet\n",
    "\n",
    "# Prophet()\n",
    "\n",
    "# this would result in:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this would result in exception:\n",
    "\n",
    "```\n",
    "ModuleNotFoundError: Prophet requires package 'prophet' to be present in the python environment,\n",
    "but 'prophet' was not found. 'prophet' is a soft dependency and not included in the base\n",
    "sktime installation. Please run: `pip install prophet` to install the prophet package.\n",
    "To install all soft dependencies, run: `pip install sktime[all_extras]`\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **F) `sktime` is extensible, write your own 3rd party plugins (open or closed)**\n",
    "\n",
    "Example: forecaster in 3rd party codebase, plug & plays to `sktime` and test framework"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "snippet from forecaster extension template (in `extension_templates` dir):\n",
    "```\n",
    "How to use this implementation template to implement a new estimator:\n",
    "- make a copy of the template in a suitable location, give it a descriptive name.\n",
    "- work through all the \"todo\" comments below\n",
    "- fill in code for mandatory methods, and optionally for optional methods\n",
    "- do not write to reserved variables: is_fitted, _is_fitted, _X, _y, cutoff, _fh,\n",
    "    _cutoff, _converter_store_y, forecasters_, _tags, _tags_dynamic, _is_vectorized\n",
    "- you can add more private methods, but do not override BaseEstimator's private methods\n",
    "    an easy way to be safe is to prefix your methods with \"_custom\"\n",
    "- change docstrings for functions and the file\n",
    "- ensure interface compatibility by sktime.utils.estimator_checks.check_estimator\n",
    "- once complete: use as a local library, or contribute to sktime via PR\n",
    "- more details:\n",
    "  https://www.sktime.net/en/stable/developer_guide/add_estimators.html\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.boxcox import BoxCoxTransformer\n",
    "from sktime.utils.estimator_checks import check_estimator\n",
    "\n",
    "res = check_estimator(BoxCoxTransformer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Learning tasks in sktime\n",
    "\n",
    "The above, with code. We revisit in more detail later."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Learning tasks - Classification, Regression, Clustering & more\n",
    "\n",
    "deal with *collections of time series* = \"panel data\"\n",
    "\n",
    "Classification = try to assign one *category* per time series, after training on time series/category examples\n",
    "\n",
    "Example: osuleaf - circumference point distance of leaves. Predict type of tree\n",
    "\n",
    "Regression = try to assign one *category* per time series, after training on time series/category examples\n",
    "\n",
    "Example: temperature/pressure/time profile of chemical reactor. Predict total purity (fraction of 1)\n",
    "\n",
    "Clustering = put different time series in a small number of similarity buckets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Panel data - `sktime` data formats\n",
    "\n",
    "Preferred format 1: `pd.DataFrame` with 2-level `MultiIndex`, (instance, time), cols= variables\n",
    "\n",
    "Preferred format 2: 3D `np.ndarray` with index (instance, variable, time)\n",
    "\n",
    "* `sktime` supports and recognizes multiple data formats for convenience and internal use, e.g., `dask`, `xarray`\n",
    "* abstract data type = \"scitype\"; in-memory specification = \"mtype\"\n",
    "* More information in tutorial on [in-memory data representations and data loading](https://www.sktime.net/en/latest/examples/AA_datatypes_and_datasets.html#In-memory-data-representations-and-data-loading)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 preferred format 1 - `pd-multiindex` specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pd-multiindex` = `pd.DataFrame` with 2-level `MultiIndex`, (instance, time), cols= variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# load an example time series panel in pd-multiindex mtype\n",
    "X, _ = load_osuleaf(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The osuleaf dataset has:\n",
    "\n",
    "* 412 individual time series instances\n",
    "* one single variable per time series instances, `dim_0`\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "# load an example time series panel in pd-multiindex mtype\n",
    "X, _ = load_basic_motions(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic motions dataset has:\n",
    "\n",
    "* 6 individual time series instances\n",
    "* six variables per time series instance, `dim_0` to `dim_5`\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 preferred format 2 - `numpy3D` specification"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`numpy3D` = 3D `np.ndarray` with index (instance, variable, time)\n",
    "\n",
    "instance/time index is interpreted as integer\n",
    "\n",
    "IMPORTANT: unlike `pd-multiindex`, this assumes:\n",
    "\n",
    "* all individual series have the same length\n",
    "* all individual series have the same index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# load an example time series panel in numpy mtype\n",
    "X, _ = load_osuleaf(return_type=\"numpy3D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The osuleaf dataset has:\n",
    "\n",
    "* 412 individual time series instances\n",
    "* one single variable per time series instances\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_basic_motions\n",
    "\n",
    "# load an example time series panel in numpy mtype\n",
    "X, _ = load_basic_motions(return_type=\"numpy3D\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The basic motions dataset has:\n",
    "\n",
    "* 6 individual time series instances\n",
    "* six variables per time series instance\n",
    "* individual time series are observed at 100 time points (the same number for all instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 loading and validity checking"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for custom data sets:\n",
    "\n",
    "1. use `pandas` `read_csv` or similar utilities to obtain a `pd.DataFrame` or `np.ndarray`\n",
    "2. try to bring the result in one of the preferred specifications\n",
    "3. use the `check_is_mtype` utility to check compliance - inspect informative error messages\n",
    "4. repeate 2-3 until the data format check passes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's pretend we just loaded this from csv\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_pd, _ = load_osuleaf(return_type=\"pd-multiindex\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's now check whether it complies with the `pd-multiindex` specification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datatypes import check_is_mtype\n",
    "\n",
    "valid, error_msg, metadata = check_is_mtype(X_pd, \"pd-multiindex\", return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# is it valid?\n",
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helpful metadata, check if this is as per expectations\n",
    "metadata"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's see what happens if it is not in the expected format.\n",
    "\n",
    "We have a `pd.DataFrame`, so if we check against `numpy3D`, it should complain:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid, error_msg, metadata = check_is_mtype(X_pd, \"numpy3D\", return_metadata=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_msg"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tells us that we should first convert into `np.ndarray` as expected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For further details on data formats, see the tutorial on [in-memory data representations and data loading](https://www.sktime.net/en/latest/examples/AA_datatypes_and_datasets.html#In-memory-data-representations-and-data-loading).\n",
    "\n",
    "The \"datatypes\" tutorial also contains:\n",
    "\n",
    "* full formal specifications of the mtypes (= machine representations)\n",
    "* common examples for loading from csv and formatting\n",
    "* utilities for loading data for commonly used benchmark problems\n",
    "\n",
    "All supported in-memory representations are python inspectable in `sktime.datatypes.MTYPE_REGISTER`\n",
    "\n",
    "Note that this includes \"exotic\", rarely used ones and representations of objects that aren't time series.\n",
    "Formats for time series panels are indicated by the `Panel` mtype.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Time Series Classification, Regression, Clustering - Basic Vignettes\n",
    "\n",
    "Above tasks are very similar to \"tabular\" classification, regression, clustering, as in `sklearn`\n",
    "\n",
    "Main distinction:\n",
    "* in \"tabular\" classification etc, one (feature) instance row vector of features\n",
    "* in TSC, one (feature) instance is a full time series, possibly unequal length, distinct index set"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: INSERT HELPFUL PICTURE HERE"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "More formally:\n",
    "\n",
    "* \"tabular\" classification: training pairs $(x_1, y_1), \\dots, (x_n, y_n)$, where $x_i$ are rows of a `pd.DataFrame` (same col types), and $y_i \\in \\mathcal{C}$ for a finite set $y_i \\in \\mathcal{C}$. We use these to train a classifier that predicts $y_* \\in \\mathcal{C}$ for a `pd.DataFrame` row $x_*$\n",
    "* time series classification: training pairs $(x_1, y_1), \\dots, (x_n, y_n)$, where $x_i$ are time series from a certain domain, and $y_i \\in \\mathcal{C}$ for a finite set $y_i \\in \\mathcal{C}$. We use these to train a classifier that predicts $y_* \\in \\mathcal{C}$ for time series $x_*$"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "very similar for time series regression, clustering - exercise left to reader :-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` design implications:\n",
    "\n",
    "* need representation of collections of time series (panels), see Section 2.1\n",
    "    * same as in \"adjacent\" learning tasks, e.g., panel forecasting\n",
    "    * same as for transformation estimators\n",
    "* algorithms that use sequentiality, can deal with unequal length etc\n",
    "* algorithms usually based on distances or kernels between time series - need to cover that in framework\n",
    "* but we can use familiar `fit` / `predict` and `scikit-learn` / `scikit-base` interface!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Time Series Classification - deployment vignette"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic deployment vignette for TSC:\n",
    "\n",
    "1. load/setup training data, `X` in a `Panel` format, `y` as 1D `np.ndarray`\n",
    "2. load/setup new data for prediction (can be done after 2 too)\n",
    "3. specify the classifier using `sklearn`-like syntax\n",
    "4. fit classifier to training data, `fit(X, y)`\n",
    "5. predict labels on new data, `predict(X_new)`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new[:2]  # smaller dataset for faster notebook runtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is in numpy3D format, but could also be pd-multiindex or other\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y is a 1D np.ndarray of labels - same length as number of instances in X_train\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 3 - specify the classifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "# example 1 - 3-NN with simple dynamic time warping distance (requires numba)\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3)\n",
    "\n",
    "# example 2:\n",
    "# 3-nearest neighbour classifier with mean (over time points) pairwise Euclidean distance\n",
    "# (requires scipy)\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we could specify any `sktime` classifier here - the rest remains the same!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all classifiers is scikit-learn / scikit-base compatible!\n",
    "# nested parameter interface via get_params, set_params\n",
    "clf.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the classifier is now fitted\n",
    "clf.is_fitted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# and we can inspect fitted parameters if we like\n",
    "clf.get_fitted_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred is an 1D np.ndarray, similar to sklearn classification output\n",
    "y_pred"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all together in one cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare osuleaf dataset (train and new)\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_new, _ = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_new = X_new[:2]  # smaller dataset for faster notebook runtime\n",
    "\n",
    "# step 3 - specify the classifier\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)\n",
    "\n",
    "# step 4 - fit/train the classifier\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.4 Time Series Classification - simple evaluation vignette"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation is simila to `sklearn` classifiers - we split a dataset and evaluate performance on the test set.\n",
    "\n",
    "This includes as additional steps:\n",
    "\n",
    "* splitting the initial, historical data, e.g., using `train_test_split`\n",
    "* comparing predictions with a held out data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.datasets import load_osuleaf\n",
    "\n",
    "# data should be split into train/test\n",
    "X_train, y_train = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X_test, y_test = load_osuleaf(split=\"test\", return_type=\"numpy3D\")\n",
    "X_test = X_test[:2]\n",
    "y_test = y_test[:2]\n",
    "\n",
    "# step 3-5 are the same\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clf = KNeighborsTimeSeriesClassifier(n_neighbors=3, distance=mean_eucl_dist)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(X_test)\n",
    "\n",
    "# for simplest evaluation, compare ground truth to predictions\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.5 Time Series Regression - basic vignettes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TSR vignettes are exactly the same as TSC, except that:\n",
    "\n",
    "* `y` in `fit` input and `predict` output should be float 1D `np.ndarray`, not categorical\n",
    "* other algorithms are commonly used and/or performant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steps 1, 2 - prepare dataset (train and new)\n",
    "from sktime.datasets import load_covid_3month\n",
    "\n",
    "X_train, y_train = load_covid_3month(split=\"train\")\n",
    "y_train = y_train.astype(\"float\")\n",
    "X_new, _ = load_covid_3month(split=\"test\")\n",
    "X_new = X_new.loc[:2]  # smaller dataset for faster notebook runtime\n",
    "\n",
    "# step 3 - specify the regressor\n",
    "from sktime.regression.distance_based import KNeighborsTimeSeriesRegressor\n",
    "\n",
    "clf = KNeighborsTimeSeriesRegressor(n_neighbors=3, distance=mean_eucl_dist)\n",
    "\n",
    "# step 4 - fit/train the regressor\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# step 5 - predict labels on new data\n",
    "y_pred = clf.predict(X_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred  # not too interesting but float"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.6 Time Series Clustering - basic vignettes"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TS clustering is similar - 1st step is also `fit`, but unsupervised\n",
    "\n",
    "i.e., no labels `y`, and next step is inspecting clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.clustering.dbscan import TimeSeriesDBSCAN\n",
    "\n",
    "# step 1 - prepare dataset (train and new)\n",
    "X, _ = load_osuleaf(split=\"train\", return_type=\"numpy3D\")\n",
    "X = X[:10]\n",
    "\n",
    "# step 2 - specify the clusterer\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.dists_kernels.compose_tab_to_panel import AggrDist\n",
    "from sktime.dists_kernels import ScipyDist\n",
    "\n",
    "mean_eucl_dist = AggrDist(ScipyDist())\n",
    "clst = TimeSeriesDBSCAN(distance=mean_eucl_dist)\n",
    "\n",
    "# step 3 - fit the clusterer to the data\n",
    "clst.fit(X)\n",
    "\n",
    "# step 4 - inspect the clustering\n",
    "clst.get_fitted_params()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Searching for estimators, estimator tags"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Estimators in `sktime` are tagged.\n",
    "\n",
    "Tags starting with \"capability\" indicate things the estimator can or cannot do, e.g.,\n",
    "\n",
    "* `\"capability:missing_values\"` - dealing with missing values\n",
    "* `\"capability:multivariate\"` - daling with multivariate input\n",
    "* `\"capability:unequal_length\"` - deaing with time series panels where the individual time series have unequal length and/or unequal index"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all tags for an estimator scitype (e.g., classifier, regressor) can be inspected by `sktime.registry.all_tags`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import all_tags\n",
    "\n",
    "all_tags(\"classifier\", as_dataframe=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "valid estimator types are listed in the `all_tags` docstring, or `sktime.registry.BASE_CLASS_REGISTER`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.registry import BASE_CLASS_REGISTER\n",
    "\n",
    "# get only fist table column, the list of types\n",
    "list(zip(*BASE_CLASS_REGISTER))[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "to find all estimators of a certain type, use `sktime.registry.all_estimators`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all classifiers in sktime\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"classifier\", as_dataframe=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for listing all estimators of a certain type with a certain capability,\n",
    "use the `filter_tags` argument of `all_estimators`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all classifiers in sktime\n",
    "# that can classify panels of time series containing missing data\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"classifier\", as_dataframe=True, filter_tags={\"capability:missing_values\": True})"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "side note:\n",
    "\n",
    "don't worry about how short the list is - when in doubt, it is always possible to pipeline with `Imputer`\n",
    "\n",
    "as in the next section :-)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Pipelines, Feature Extraction, Tuning, Composition\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "similar to `sklearn` for \"tabular\" classification, regression, etc,\n",
    "\n",
    "`sktime` has a rich set of tools for:\n",
    "\n",
    "* feature extraction via transformers\n",
    "* pipeline transformers with any estimator\n",
    "* tuning individual estimators or pipelines via grid search and similar\n",
    "* building ensembles out of individual estimators, or other composites\n",
    "\n",
    "`sktime` is also fully interoperable with `sklearn` interface if `numpy` based data mtypes are used\n",
    "\n",
    "(although this loses support for unequal length time series)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Primer on `sktime` transformers for feature extraction"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all `sktime` transformers work natively with panel data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_osuleaf\n",
    "from sktime.transformations.series.detrend import Detrender\n",
    "\n",
    "# load some panel data\n",
    "X, _ = load_osuleaf(return_type=\"pd-multiindex\")\n",
    "\n",
    "# specify a linear detrender\n",
    "detrender = Detrender()\n",
    "\n",
    "# detrend X by removing linear trend from each instance\n",
    "X_detrended = detrender.fit_transform(X)\n",
    "X_detrended.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for panel tasks such as TSC, TSR, clustering, there are two distinctions to be aware of:\n",
    "\n",
    "* series-to-series transformers transform individual series to series, panels to panels. E.g., instance-wise detrender above\n",
    "* series-to-primitive transformers transform individual series to a set of tabular features. E>g., summary feature extractor\n",
    "\n",
    "either type of transform can be instance-wise:\n",
    "\n",
    "* instance-wise transforms use only the i-th series to transform the i-th series. E.g., instance-wise detrender\n",
    "* non-instance-wise transforms train on all series to transform the i-th series. E.g., PCA, overall mean detrender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example of a series-to-primitive transformer\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "# specify summary transformer\n",
    "summary_trafo = SummaryTransformer()\n",
    "\n",
    "# extract summary features - one per instance in the panel\n",
    "X_summaries = summary_trafo.fit_transform(X)\n",
    "X_summaries"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just like classifiers, we can search for transformers of either type via the right tag:\n",
    "\n",
    "* `\"scitype:transform-input\"` and `\"scitype:transform-output\"` define input and output, e.g., \"series-to-series\" (both are scitype strings)\n",
    "* `\"scitype:instancewise\"` is boolean and tells us whether the transform is instance-wise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example: looking for all series-to-primitive transformers that are instance-wise\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\n",
    "    \"transformer\",\n",
    "    as_dataframe=True,\n",
    "    filter_tags={\n",
    "        \"scitype:transform-input\": \"Series\",\n",
    "        \"scitype:transform-output\": \"Primitives\",\n",
    "        \"scitype:instancewise\": True,\n",
    "    },\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further details on transformations and feature extraction can be found in the tutorial 3, transformers.\n",
    "\n",
    "All composition steps therein (e.g., chaining, column subsetting) work together with all estimator types in `sktime`, including classifiers, regressors, clusterers."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Pipelines for time series panel tasks"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all panel estimators pipeline with `sktime` transformers, via the `*` dunder or `make_pipeline`.\n",
    "\n",
    "The pipeline does the following:\n",
    "\n",
    "* in `fit`: runs the transformers' `fit_transform` in sequence, then `fit` of the panel estimator\n",
    "* in `predict`, runs the fitted transformers' `transform` in sequence, then `predict` of the panel estimator\n",
    "\n",
    "(same logic as for `sklearn` pipelines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "from sktime.transformations.series.exponent import ExponentTransformer\n",
    "\n",
    "pipe = ExponentTransformer() * KNeighborsTimeSeriesClassifier()\n",
    "\n",
    "# this constructs a ClassifierPipeline, which is also a classifier\n",
    "pipe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alternative to construct:\n",
    "from sktime.pipeline import make_pipeline\n",
    "\n",
    "pipe = make_pipeline(ExponentTransformer(), KNeighborsTimeSeriesClassifier())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_unit_test\n",
    "\n",
    "X_train, y_train = load_unit_test(split=\"TRAIN\")\n",
    "X_test, _ = load_unit_test(split=\"TEST\")\n",
    "\n",
    "# this is a forecaster with the same interface as knn-classifier\n",
    "# first applies exponent transform, then knn-classifier\n",
    "pipe.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` transformers pipeline with `sklearn` classifiers!\n",
    "\n",
    "This allows to build \"time series feature extraction then `sklearn` classify`\" pipelines:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sktime.transformations.series.summarize import SummaryTransformer\n",
    "\n",
    "# specify summary transformer\n",
    "summary_rf = SummaryTransformer() * RandomForestClassifier()\n",
    "\n",
    "summary_rf.fit(X_train, y_train)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Using transformers to deal with unequal length or missing values"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pro tipp: useful transformers to pipeline are those that \"improve\" capabilities!\n",
    "\n",
    "Search for these transformer tags:\n",
    "\n",
    "* `\"capability:unequal_length:removes\"` - ensures all instances in the panel have equal length afterwards. Examples: padding, cutting, resampling.\n",
    "* `\"capability:missing_values:removes\"` - removes all missing values from the data (e.g., series, panel) passed to it. Example: mean imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transformers that guarantee that the output is equal length and equal index\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"transformer\", as_dataframe=True, filter_tags={\"capability:unequal_length:removes\": True })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# all transformers that guarantee the output has no missing values\n",
    "from sktime.registry import all_estimators\n",
    "\n",
    "all_estimators(\"transformer\", as_dataframe=True, filter_tags={\"capability:missing_values:removes\": True })"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "minor note:\n",
    "\n",
    "some transformers guarantee \"no missing values\" under some conditions but not always, e.g., `TimeBinAggregate`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let's check the tags in one example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list all classifiers in sktime\n",
    "from sktime.classification.feature_based import MatrixProfileClassifier\n",
    "\n",
    "no_missing_clf = MatrixProfileClassifier()\n",
    "\n",
    "no_missing_clf.get_tags()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.transformations.series.impute import Imputer\n",
    "\n",
    "clf_can_do_missing = Imputer() * MatrixProfileClassifier()\n",
    "\n",
    "clf_can_do_missing.get_tags()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.4 Tuning and model selection"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` classifiers are compatible with `sklearn` model selection and composition tools using `sktime` data formats.\n",
    "\n",
    "This extends to grid tuning and cross-validation, as long as `numpy` based formats or length/instance indexed formats are used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sktime.datasets import load_unit_test\n",
    "\n",
    "X_train, y_train = load_unit_test(split=\"TRAIN\")\n",
    "X_test, _ = load_unit_test(split=\"TEST\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation using the `sklearn` `cross_val_score` and `KFold` functionality:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold, cross_val_score\n",
    "from sktime.classification.feature_based import MatrixProfileClassifier\n",
    "\n",
    "clf = MatrixProfileClassifier()\n",
    "\n",
    "cross_val_score(clf, X_train, y=y_train, cv=KFold(n_splits=4))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameter tuning using `sklearn` `GridSearchCV`, we tune the _k_ and distance measure for a K-NN classifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sktime.classification.distance_based import KNeighborsTimeSeriesClassifier\n",
    "\n",
    "knn = KNeighborsTimeSeriesClassifier()\n",
    "param_grid = {\"n_neighbors\": [1, 5], \"distance\": [\"euclidean\", \"dtw\"]}\n",
    "parameter_tuning_method = GridSearchCV(knn, param_grid, cv=KFold(n_splits=4))\n",
    "\n",
    "parameter_tuning_method.fit(X_train, y_train)\n",
    "y_pred = parameter_tuning_method.predict(X_test)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.5 Advanced Composition cheat sheet - AutoML, bagging, ensembles"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* common ensembling patterns: `BaggingClassifier`, `WeightedEnsembleClassifier`\n",
    "* composability with `sklearn` classifier, regressor building blocks still applies\n",
    "* AutoML can be achieved by combining tuning with `MultiplexClassifier` or `MultiplexTransformer`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pro tipp: bagging with a fixed single column subset can be used to turn an univariate classifier into a multivariate classifier!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Appendix - Extension guide"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`sktime` is meant to be easily extensible, for direct contribution to `sktime` as well as for local/private extension with custom methods.\n",
    "\n",
    "To extend `sktime` with a new local or contributed estimator, a good workflow to follow is:\n",
    "\n",
    "0. find the right extension template for the type of estimator you want to add - e.g., classifier, regressor, clusterer, etc. The extension templates are located in the [`extension_templates](https://github.com/sktime/sktime/blob/main/extension_templates) directory\n",
    "1. read through the extension template - this is a `python` file with `todo` blocks that mark the places in which changes need to be added.\n",
    "2. optionally, if you are planning any major surgeries to the interface: look at the base class - note that \"ordinary\" extension (e.g., new algorithm) should be easily doable without this.\n",
    "3. copy the extension template to a local folder in your own repository (local/private extension), or to a suitable location in your clone of the `sktime` or affiliated repository (if contributed extension), inside `sktime.[name_of_task]`; rename the file and update the file docstring appropriately.\n",
    "4. address the \"todo\" parts. Usually, this means: changing the name of the class, setting the tag values, specifying hyper-parameters, filling in `__init__`, `_fit`, `_predict` and/or other methods (for details see the extension template). You can add private methods as long as they do not override the default public interface. For more details, see the extension template.\n",
    "5. to test your estimator manually: import your estimator and run it in the basic vignettes above.\n",
    "6. to test your estimator automatically: call `sktime.tests.test_all_estimators.check_estimator` on your estimator. You can call this on a class or object instance. Ensure you have specified test parameters in the `get_test_params` method, according to the extension template.\n",
    "\n",
    "In case of direct contribution to `sktime` or one of its affiliated packages, additionally:\n",
    "* add yourself as an author to the code, and to the `CODEOWNERS` for the new estimator file(s).\n",
    "* create a pull request that contains only the new estimators (and their inheritance tree, if it's not just one class), as well as the automated tests as described above.\n",
    "* in the pull request, describe the estimator and optimally provide a publication or other technical reference for the strategy it implements.\n",
    "* before making the pull request, ensure that you have all necessary permissions to contribute the code to a permissive license (BSD-3) open source project."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "### Credits: notebook 2 - time series panel tasks - classification, regression, clustering\n",
    "\n",
    "notebook creation: fkiraly, achieveordie"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sktime-dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
